# 8、高级功能和概念

本章介绍了 Reactor 的高级功能和概念，包括：

    （1）共享操作符用法
    （2）热与冷
    （3）使用 ConnectableFlux 向多个订阅者广播
    （4）三种分批的方式
    （5）用 ParallelFlux 并行工作
    （6）替换默认 Schedulers
    （7）使用全局钩子
    （8）向反应式序列添加上下文
    （9）处理需要清理的对象
    （10）空安全

## 8.1、共享操作符用法

从清理代码的角度来看，代码重用通常是一件好事。Reactor 提供了一些模式，可以帮助你重用和共享代码，特别是对于你可能希望在代码库中定期应用的操作符或操作符组合。如果将操作符链视为菜谱，则可以创建操作符菜谱的烹饪书。

### 8.1.1、使用 transform 操作符

transform 操作符允许你将操作符链的一部分封装到函数中。该函数在装配时应用原始操作符链，以使用封装的操作符对其进行扩充。这样做对序列的所有订阅者应用相同的操作，基本上相当于直接链接操作符。下面的代码显示了一个示例：
```
Function<Flux<String>, Flux<String>> filterAndMap =
f -> f.filter(color -> !color.equals("orange"))
      .map(String::toUpperCase);

Flux.fromIterable(Arrays.asList("blue", "green", "orange", "purple"))
    .doOnNext(System.out::println)
    .transform(filterAndMap)
    .subscribe(d -> System.out.println("Subscriber to Transformed MapAndFilter: "+d));
```
上面的示例生成以下输出：

    blue
    Subscriber to Transformed MapAndFilter: BLUE
    green
    Subscriber to Transformed MapAndFilter: GREEN
    orange
    purple
    Subscriber to Transformed MapAndFilter: PURPLE

### 8.1.2、使用 compose 操作符

compose 操作符类似于 transform，还允许你在函数中封装操作符。主要区别在于，此函数是以每个订阅者为基础应用于原始序列的。这意味着该函数实际上可以为每个订阅生成不同的操作符链（通过维护某些状态）。下面的代码显示了一个示例：
```
AtomicInteger ai = new AtomicInteger();
Function<Flux<String>, Flux<String>> filterAndMap = f -> {
    if (ai.incrementAndGet() == 1) {
return f.filter(color -> !color.equals("orange"))
        .map(String::toUpperCase);
    }
    return f.filter(color -> !color.equals("purple"))
            .map(String::toUpperCase);
};

Flux<String> composedFlux =
Flux.fromIterable(Arrays.asList("blue", "green", "orange", "purple"))
    .doOnNext(System.out::println)
    .compose(filterAndMap);

composedFlux.subscribe(d -> System.out.println("Subscriber 1 to Composed MapAndFilter :"+d));
composedFlux.subscribe(d -> System.out.println("Subscriber 2 to Composed MapAndFilter: "+d));
```
上面的示例生成以下输出：

    blue
    Subscriber 1 to Composed MapAndFilter :BLUE
    green
    Subscriber 1 to Composed MapAndFilter :GREEN
    orange
    purple
    Subscriber 1 to Composed MapAndFilter :PURPLE
    blue
    Subscriber 2 to Composed MapAndFilter: BLUE
    green
    Subscriber 2 to Composed MapAndFilter: GREEN
    orange
    Subscriber 2 to Composed MapAndFilter: ORANGE
    purple

## 8.2、热与冷

到目前为止，我们认为所有 Flux（和 Mono）都是一样的：它们都表示异步的数据序列，在订阅之前什么都不会发生。

但实际上，发布者有两大类：热与冷。

上面的描述适用于冷发布者家族。它们为每个订阅重新生成数据。如果没有创建订阅，则永远不会生成数据。

想想 HTTP 请求：每个新订阅者都会触发一个 HTTP 调用，但是如果没有人对结果感兴趣，则不会进行调用。

另一方面，热发布者并不依赖于任何数量的订阅者。它们可能会立即开始发布数据，并在新订阅者进入时继续这样做（在这种情况下，所述订阅者将只看到在其订阅后发出的新元素）。对于热发布者来说，在你订阅之前确实会发生一些事情。

在 Reactor 中几个热操作符的一个例子是 just：它直接在装配时捕获该值，并在以后将其回放给订阅它的任何人。要重用 HTTP 调用类比，如果捕获的数据是 HTTP 调用的结果，那么在实例化 just 时只执行一个网络调用。

若要将 just 转换为冷发布者，可以使用 defer。在我们的示例中，它将 HTTP 请求延迟到订阅时（并将导致对每个新订阅的单独网络调用）。

Reactor 中大多数其他热发布者都继承了 Processor。

再举两个例子。以下代码展示了第一个示例：
```
Flux<String> source = Flux.fromIterable(Arrays.asList("blue", "green", "orange", "purple"))
                          .map(String::toUpperCase);

source.subscribe(d -> System.out.println("Subscriber 1: "+d));
source.subscribe(d -> System.out.println("Subscriber 2: "+d));
```
第一个例子产生以下输出：

    Subscriber 1: BLUE
    Subscriber 1: GREEN
    Subscriber 1: ORANGE
    Subscriber 1: PURPLE
    Subscriber 2: BLUE
    Subscriber 2: GREEN
    Subscriber 2: ORANGE
    Subscriber 2: PURPLE

两个订阅者都捕获所有四种颜色，因为每个订阅者都会导致 Flux 上的操作符定义的进程运行。

将第一个例子和第二个例子进行比较，如下面代码所示：
```
DirectProcessor<String> hotSource = DirectProcessor.create();

Flux<String> hotFlux = hotSource.map(String::toUpperCase);


hotFlux.subscribe(d -> System.out.println("Subscriber 1 to Hot Source: "+d));

hotSource.onNext("blue");
hotSource.onNext("green");

hotFlux.subscribe(d -> System.out.println("Subscriber 2 to Hot Source: "+d));

hotSource.onNext("orange");
hotSource.onNext("purple");
hotSource.onComplete();
```
第二个例子产生以下输出：

    Subscriber 1 to Hot Source: BLUE
    Subscriber 1 to Hot Source: GREEN
    Subscriber 1 to Hot Source: ORANGE
    Subscriber 2 to Hot Source: ORANGE
    Subscriber 1 to Hot Source: PURPLE
    Subscriber 2 to Hot Source: PURPLE

订阅者 1 捕获了四种颜色。订阅者 2 在前两种颜色生成后创建，只捕获后两种颜色。这种差异导致了在输出中“ORANGE”和“PURPLE”的量翻倍。不管订阅是何时附加的，此 Flux 上的操作符所描述的进程都将运行。

## 8.3、使用 ConnectableFlux 向多个订阅者广播

有时，你不仅希望将某些处理推迟到一个订阅者的订阅时，而且实际上可能希望其中几个订阅者会合，然后出触发订阅和数据生成。

这就是 ConnectableFlux 的用途。在返回 ConnectableFlux 的 Flux API 中包含两个主要模式：publish 和 repaly。

（1）publish 通过将这些请求转发到源，动态地尝试维护来自不同订阅者的需求（就背压而言）。最值得注意的是，如果任何订阅者的挂起请求为 0，则 publish 将暂停对源的请求。

（2）replay 缓存第一次订阅看到的数据，达到可配置的限制（时间和缓冲区大小）。它将数据重放给后续订阅者。

ConnectableFlux 提供了管理下游订阅和原始源订阅的其他方法，这些方法包括：

    （1）一旦达到对 Flux 的足够订阅，就可以手动调用 connect()。从而触发对上游源的订阅。
    （2）一旦产生了 n 个订阅，autoConnect(n) 就可以自动做同样的任务。
    （3）refCount(n) 不仅自动跟踪到来的订阅，还能检测到订阅何时被取消。如果没有跟踪到足够多的订阅者，则源被“断开连接”，如果出现其他订阅者，将导致稍后对源的新订阅。
    （4）refCount(int,Duration) 添加了一个“宽限期”：一旦跟踪的订阅者数量太少，它将在断开源连接之前等待该持续时间，从而可能允许足够多的新订阅者进入并再次越过连接阈值。

考虑下面示例：
```
Flux<Integer> source = Flux.range(1, 3)
                           .doOnSubscribe(s -> System.out.println("subscribed to source"));

ConnectableFlux<Integer> co = source.publish();

co.subscribe(System.out::println, e -> {}, () -> {});
co.subscribe(System.out::println, e -> {}, () -> {});

System.out.println("done subscribing");
Thread.sleep(500);
System.out.println("will now connect");

co.connect();
```
上面的代码产生以下输出：

    done subscribing
    will now connect
    subscribed to source
    1
    1
    2
    2
    3
    3

使用 autoConnect：
```
Flux<Integer> source = Flux.range(1, 3)
                           .doOnSubscribe(s -> System.out.println("subscribed to source"));

Flux<Integer> autoCo = source.publish().autoConnect(2);

autoCo.subscribe(System.out::println, e -> {}, () -> {});
System.out.println("subscribed first");
Thread.sleep(500);
System.out.println("subscribing second");
autoCo.subscribe(System.out::println, e -> {}, () -> {});
```
以上代码产生以下输出：

    subscribed first
    subscribing second
    subscribed to source
    1
    1
    2
    2
    3
    3

## 8.4、三种分批的方式

当有很多元素并且想要把它们分批处理的时候，在 Reactor 中有三个主要的解决方案：分组、窗口化和缓冲。这三者在概念上很接近，因为它们将 Flux<T> 重新分配到一个集合中。分组和窗口化创建一个 Flux<Flux<T>>，而缓冲聚合成一个 Collection<T>。

### 8.4.1、用 Flux<GroupedFlux<T>> 分组

分组是通过一个 key 将 Flux<T> 分成多个批次的行为。

相关操作符是 groupBy。

每个组都表示为一个 GroupedFlux<T>，它允许你通过其 key() 方法检索 key。

这些小组的内容没有必要的连续性。一旦一个源元素产生一个新的键，这个键的组就被打开，并且与该键匹配的元素最终出现在该组中（几个组可以同时打开）。

这意味着这些组：

    （1）它们总是不相交的（一个源元素只能属于 1 个组）。
    （2）它们可以包含原始序列中不同位置的元素。
    （3）它们永远不会是空的。
```
StepVerifier.create(
    Flux.just(1, 3, 5, 2, 4, 6, 11, 12, 13)
        .groupBy(i -> i % 2 == 0 ? "even" : "odd")
        .concatMap(g -> g.defaultIfEmpty(-1) //if empty groups, show them
                .map(String::valueOf) //map to string
                .startWith(g.key())) //start with the group's key
    )
    .expectNext("odd", "1", "3", "5", "11", "13")
    .expectNext("even", "2", "4", "6", "12")
    .verifyComplete();
```
警告：分组最适合具有中等到较低数量组的情况。还必须强制使用组（例如，由 flatMap 使用），以便 groupBy 继续从上游获取数据并为更多组提供数据。有时，这两个约束相乘并导致挂起，例如当基数较高且使用组的 flatMap 的并发性太低时。

### 8.4.2、用 Flux<Flux<T>> 窗口化

窗口化是根据大小、时间、边界定义谓词或边界定义 Publisher 的标准将源 Flux<T> 拆分为窗口的行为。

相关的操作符是 window、windowTimeout、windowUtil、windowWhile 和 windowWhen。

与 groupBy 根据传入的键随机交叠不同，大多数时间窗口是按顺序打开的。

不过，有些变体仍然可以交叠。例如，在 window(int maxSize,int skip) 中，maxSize 参数是窗口关闭后的元素数，skip 参数是源中打开新窗口后的元素数。因此，如果 maxSize > skip ，则新窗口在前一个窗口关闭之前打开，并且这两个窗口会交叠。

下面示例展示了交叠的窗口：
```
StepVerifier.create(
    Flux.range(1, 10)
        .window(5, 3) //overlapping windows
        .concatMap(g -> g.defaultIfEmpty(-1)) //show empty windows as -1
    )
        .expectNext(1, 2, 3, 4, 5)
        .expectNext(4, 5, 6, 7, 8)
        .expectNext(7, 8, 9, 10)
        .expectNext(10)
        .verifyComplete();
```
注释：使用反向配置（maxSize < skip），会删除源中的某些元素，并且这些元素不是任何窗口的一部分。

在通过 windowUtil 和 windowWhile 进行基于谓词的窗口化时，如果后续的源元素与谓词不匹配，也会导致空窗口，如下面的示例所示：
```
StepVerifier.create(
    Flux.just(1, 3, 5, 2, 4, 6, 11, 12, 13)
        .windowWhile(i -> i % 2 == 0)
        .concatMap(g -> g.defaultIfEmpty(-1))
    )
        .expectNext(-1, -1, -1) //respectively triggered by odd 1 3 5
        .expectNext(2, 4, 6) // triggered by 11
        .expectNext(12) // triggered by 13
        // however, no empty completion window is emitted (would contain extra matching elements)
        .verifyComplete();
```
### 8.4.3、用 Flux<List<T>> 缓冲

缓冲类似于窗口化，有如下的变化：它不发送窗口（每个窗口都是 Flux<T>），而是发送缓冲区（缓冲区是 Collection<T>，默认情况下是 List<T>）。

与窗口化相对应的缓冲操作符：buffer、bufferTimeout、bufferUntil、bufferWhile 和 bufferWhen。

在相应的窗口操作符打开窗口的地方，缓冲操作符将创建一个新集合并开始向其添加元素。在窗口关闭的地方，缓冲操作符发送元素。

缓冲还会导致删除源元素或产生交叠的缓冲区，如下所示：
```
StepVerifier.create(
    Flux.range(1, 10)
        .buffer(5, 3) //overlapping buffers
    )
        .expectNext(Arrays.asList(1, 2, 3, 4, 5))
        .expectNext(Arrays.asList(4, 5, 6, 7, 8))
        .expectNext(Arrays.asList(7, 8, 9, 10))
        .expectNext(Collections.singletonList(10))
        .verifyComplete();
```
与窗口化不同的是，bufferUntil 和 bufferWhile 不会发送空缓冲区，如下所示：
```
StepVerifier.create(
    Flux.just(1, 3, 5, 2, 4, 6, 11, 12, 13)
        .bufferWhile(i -> i % 2 == 0)
    )
    .expectNext(Arrays.asList(2, 4, 6)) // triggered by 11
    .expectNext(Collections.singletonList(12)) // triggered by 13
    .verifyComplete();
```
## 8.5、用 ParallelFlux 并行工作

随着多核架构成为当今的主流，能够轻松地并行化工作是很重要的。Reactor 通过提供一种特殊的类型 ParallelFlux 来帮助实现这一点，它公开了为并行工作而优化的操作符。

要获取 ParallelFlux，可以在任何 Flux 上使用 parallel() 操作符。这种方法本身并不能使工作并行化。相反，它将工作负载划分为“rails”（默认情况下，rails 的数量与 CPU 核心的数量相同）。

为了告诉产生的 ParallelFlux 在哪里执行每个 rail（并通过扩展，并行地执行 rails），必须使用 runOn(Scheduler)。请注意，对于并行工作，建议使用专用调度器：Schedulers.parallel()。

比较接下来的两个示例，下面的代码中显示了其中的第一个：
```
Flux.range(1, 10)
    .parallel(2) 
    .subscribe(i -> System.out.println(Thread.currentThread().getName() + " -> " + i));
```
    （1）我们强制使用多个 rails，而不是依赖于 CPU 核心的数量。 

下面的代码展示了第二个示例：
```
Flux.range(1, 10)
    .parallel(2)
    .runOn(Schedulers.parallel())
    .subscribe(i -> System.out.println(Thread.currentThread().getName() + " -> " + i));
```
第一个示例产生以下输出：

    main -> 1
    main -> 2
    main -> 3
    main -> 4
    main -> 5
    main -> 6
    main -> 7
    main -> 8
    main -> 9
    main -> 10

第二个在两个线程上正确地并行，如下所示：

    parallel-1 -> 1
    parallel-2 -> 2
    parallel-1 -> 3
    parallel-2 -> 4
    parallel-1 -> 5
    parallel-2 -> 6
    parallel-1 -> 7
    parallel-1 -> 9
    parallel-2 -> 8
    parallel-2 -> 10	

如果在并行处理序列后，希望恢复到“正常”Flux，并以顺序方式应用到操作符链的其余部分，则可以对 ParallelFlux 使用 sequential() 方法。

请注意，如果你使用 Subscriber 订阅 ParallelFlux，那么会隐式地应用 sequential()，但是在使用基于 lambda 的 subscribe 变体时不会这样做。

还要注意，subscribe(Subscriber<T>) 合并了所有的 rails，而 subscribe(Consumer<T>) 运行所有的 rails。

你还可以通过 groups() 方法以 Flux<GroupedFlux<T>> 的形式访问单独的 rails 或“组”，并通过 composeGroup() 方法对它们应用其他的操作符。

## 8.6、替换默认 Schedulers

正如我们在“Threading 和 Schedulers”一节中看到的，Reactor Core 提供了几个 Scheduler 实现。虽然你总是可以通过 new* 工厂方法创建新实例，但是每个 Scheduler 类型都有一个默认的单例实例，可以通过直接的工厂方法（例如：Schedulers.elastic() 与 Schedulers.newElastic()）访问该实例。

在未显式指定 Scheduler 时，这些默认实例是需要 Scheduler 才能工作的操作符所使用的实例。例如，Flux#delayElements(Duration) 使用 Schedulers.parallel() 实例。

但是，在某些情况下，你可能需要以交叉方式用其他方法更改这些默认实例，而不必确保你调用的每个操作符都将特定的 Scheduler 作为参数。一个例子是通过包装实际的调度器来测量每个调度任务所花费的时间，以便进行检测。换句话说，你可能需要更改默认 Schedulers。

可以通过 Schedulers.Factory 类更改默认调度器。默认情况下，Factory 通过类似命名的方法创建所有标准的 Scheduler。每一个都可以用自定义实现重写。

另外，Factory 公开了一个额外的定制方法：decorateExecutorService。它在创建由 ScheduledExecutorService 支持的每个 reactor-core 调度器（甚至是非默认实例，例如通过调用 Schedulers.newParallel() 创建的实例）期间被调用。

这允许你优化要使用的 ScheduledExecutorService：默认的一个将作为 Supplier 公开，并且，根据正在配置的 Scheduler 类型，你可以选择完全绕开该 Supplier 实例并返回你自己的实例，或者你可以通过 get() 方法获取默认实例并包装它。

重要的是：一旦你创建了适合你需要的 Factory，你必须通过 Schedulers.setFactory(Factory) 来安装它。

最后，Schedulers 中还有最后一个可定制的钩子：onHandleError。每当提交给 Scheduler 的 Runnable 接口任务抛出异常时，都会调用此钩子（请注意，如果为运行该任务的线程设置了 UncaughtExceptionHandler，则会调用该处理程序(handler)和钩子）。

## 8.7、使用全局钩子

Reactor 还有另一类可配置回调，由 Reactor 操作符在各种情况下调用。它们都设置在 Hooks 类中，分为三类：

（1）[丢弃钩子](https://projectreactor.io/docs/core/3.2.11.RELEASE/reference/#hooks-dropping)

（2）[内部错误钩子](https://projectreactor.io/docs/core/3.2.11.RELEASE/reference/#hooks-internal)

（3）[装配钩子](https://projectreactor.io/docs/core/3.2.11.RELEASE/reference/#hooks-assembly)

### 8.7.1、丢弃钩子

当操作符的源不符合反应流规范时，将调用 Dropping hooks。这类错误超出了正常的执行路径（也就是说，它们不能通过 onError 传播）。

通常，Publisher 会在操作符上调用 onNext，尽管之前已经在其上调用了 onCompleted。在这种情况下，将删除 onNext 值。对于无关的 onError 信号也是如此。

相应的钩子：onNextDropped 和 onErrorDropped 允许你为这些 drops 提供一个全局 Consumer。例如，如果需要，你可以使用它来记录与某个值相关联的 drop 和 cleanup 资源（因为它永远不会到达反应式链的其余部分）。

连续设置两次钩子是附加的：你提供的每个消费者都会被调用。可以使用 Hooks.resetOn*Dropped() 方法将钩子完全重置为默认值。

### 8.7.2、内部错误钩子

其中一个钩子 onOperatorError 是操作符在执行它们的 onNext、onError 和 onComplete 方法期间抛出意外异常时调用的。

与前一个类别不同，它仍在正常的执行路径内。一个典型的例子是带有 map 函数的 map 操作符，该函数抛出 Exception（例如除以零）。此时仍有可能通过 onError 的常规通道，而这正是操作符所做的。

首先，它通过 onOperatorError 传递 Exception。该钩子允许你检查错误（y以及相关的指示值）并更改 Exception。当然，你也可以在一旁执行一些操作，例如记录并返回原始异常。

请注意，onOperatorError 钩子可以设置多次：你可以为特定的 BiFunction 提供一个 String 标识符，随后使用不同键的调用会将所有执行的函数连接起来。另一方面，重复使用同一个键两次可以替换先前设置的函数。

因此，默认的钩子行为可以完全重置（使用 Hooks.resetOnOperatorError()）或仅部分重置特定键（使用 Hooks.resetOnOperatorError(String)）。

### 8.7.3、装配钩子

这些钩子与操作符的生命周期紧密相连。它们在装配（即，实例化）操作符链时被调用。onEachOperator 允许你通过返回不同的 Publisher，在装配到链中时动态更改每个操作符。onLastOperator 与此类似，只是它只在 subscribe 调用之前调用链中的最后一个操作符。

如果你想用一个横切（cross-cutting）的 Subscriber 实现来装饰所有的操作符，则你可以查看 Operators#lift* 方法来帮助你处理各种类型的 Reactor Publishers（Flux、Mono、ParallelFlux、GroupedFlux、ConnectableFlux），以及它们的 Fuseable 版本。

与 onOperatorError 一样，这些钩子是累积的（cumulative），可以用键标识。它们也可以部分或全部重置。

### 8.7.4、钩子预设

Hooks 工具类提供了两个预先设置的钩子。这些都是默认行为的替代方法，你可以通过调用它们相应的方法来使用它们，而不是自己生成钩子。

（1）onNextDroppedFail()：onNextDropped 用于抛出 Exceptions.failWithCancel() 异常。它现在默认在 DEBUG 级别记录丢失的值。要返回到抛出的旧默认行为，请使用 onNextDroppedFail()。

（2）onOperatorDebug()：此方法激活调试模式。它绑定到 onOperatorError 钩子中，因此调用 resetOnOperatorError() 也会重置它。它可以通过 resetOnOperatorDebug() 独立重置，因为它在内部使用特定的键。

## 8.8、向反应式序列添加上下文

从命令式编程的角度转换到反应式编程思维时遇到的一大技术挑战在于如何处理线程。

与你可能习惯的相反，在反应式编程中，一个线程可以用来处理几个大致同时运行的异步序列 (实际上，在非阻塞锁定步骤中)。执行也可以轻松且经常从一个线程跳到另一个线程。

对于使用依赖于线程模型更 “稳定” 的功能的开发者来说，这种安排尤其困难，例如：ThreadLocal。由于它允许你将数据与线程相关联，因此在反应式上下文中使用它变得很棘手。因此，依赖于 ThreadLocal 的库在与 Reactor 一起使用时至少会带来新的挑战。最坏的情况是，它们工作不好，甚至失败。使用 Logback 的 MDC 来存储和记录相关 IDs 是这种情况的主要例子。

ThreadLocal 用法的通常解决方法是，例如，使用 Tuple2<T，C> 沿业务数据 T 按顺序移动上下文数据 C。这看起来不太好，并将正交关系（上下文数据）泄漏到方法和 Flux 签名中。

自 3.1.0 版以来，Reactor 提供了一个高级功能，它与 ThreadLocal 有些相似，但应用于 Flux 或 Mono 而不是 Thread:Context。

为了说明它是怎样的，这里有一个非常简单的例子，既可以向 Context 写入，也可以从中读取。
```
String key = "message";
Mono<String> r = Mono.just("Hello")
                .flatMap( s -> Mono.subscriberContext()
                                   .map( ctx -> s + " " + ctx.get(key)))
                .subscriberContext(ctx -> ctx.put(key, "World"));

StepVerifier.create(r)
            .expectNext("Hello World")
            .verifyComplete();
```
在下面的部分中，我们将学习 Context 以及如何使用它，以便你最终理解上面的示例。

重要的：这是一个更针对库开发者的高级功能。它需要对 Subscription 的生命周期有很好的理解，并且是为负责订阅的库设计的。

### 8.8.1、Context API

Context 是一个类似于 Map 的接口：它存储键值对，并允许你获取按其键存储的值。更具体地说：

    （1）key 和 values 都是 Object 类型，因此 Context 可以包含来自不同库和源的任意数量的高度不同的值。
    （2）Context 是不可变的。
    （3）使用 put(Object key，Object value) 存储键值对，返回一个新的 Context 实例。还可以使用 putAll(Context) 将两个上下文合并为一个新上下文。
    （4）你可以用 hasKey(Object key) 检查该键是否存在。
    （5）使用 getOrDefault(Object key,T defaultValue)检索值（强制转换为 T），或者，如果 Context 没有该键，则返回默认值。
    （6）使用 getOrEmpty(Object key) 获取 Optional<T>(上下文尝试将存储的值强制转换为 T)。
    （7）使用 delete(Object key) 删除与键关联的值，返回新 Context。

提示：

创建 Context 时，可以使用静态方法 Context.of 创建最多包含 5 个键值对的预值上下文。它们获取 2、4、6、8 或 10 个 Object 实例，每对 Object 实例都是要添加到 Context 中的键值对。

或者，也可以使用 Context.empty() 创建空 Context。

### 8.8.2、把 Context 与 Flux 和 Writing 联系起来

要使上下文有用，必须将其绑定到特定序列，并且链中的每个操作符都可以访问它。注意，该操作符必须是 Reactor 自身的操作符，因为 Context 特定于 Reactor。

实际上，Context 是与每个 Subscriber 绑定在一个链上的。它使用 Subscription 传播机制使自己对每个操作符可用，从最后的订阅开始并向上移动链。

为了填充只能在订阅时完成的 Context，需要使用 subscriberContext 操作符。

使用 subscriberContext (Context)，合并您提供的 Context 和来自下游的 Context （请记住，该 Context 是从链的底部向顶部传播的）。这是通过对 putAll 的调用来完成的，为上游产生了一个新的 Context。

提示：你还可以使用更高级的 subscriberContext(Function<Context, Context>)。它从下游接收 Context 的状态，并允许你根据需要放置或删除值，从而返回要使用的新 Context。你甚至可以决定返回一个完全不同的实例，尽管实际上并不推荐这样做（这样做可能会影响依赖于 Context 的第三方库）。

### 8.8.3、读取 Context

填充 Context 是一个方面，但从中检索数据同样重要。大多数情况下，将信息放到 Context 中的责任在最终用户端，而利用该信息的责任在第三方库端，因为此类库通常位于客户端代码的上游。

从上下文读取数据的工具是静态 Mono.subscriberContext() 方法。

### 8.8.4、简单示例

本节中的示例是为了更好地理解使用 Context 的一些注意事项。

让我们首先回顾一下介绍中的简单示例，并详细介绍一下：
```
String key = "message";
Mono<String> r = Mono.just("Hello")
                .flatMap( s -> Mono.subscriberContext() 
                                   .map( ctx -> s + " " + ctx.get(key))) 
                .subscriberContext(ctx -> ctx.put(key, "World")); 

StepVerifier.create(r)
            .expectNext("Hello World") 
            .verifyComplete();
```
    （1）操作符链以对 subscriberContext(Function) 调用结束，该调用将“World”放入键“message”下的 Context 中。
    （2）我们在源元素上执行 flatMap，以用 Mono.subscriberContext() 具体化 Context。
    （3）然后，我们使用 map 提取与“message”相关联的数据，并将其与原始单词连接起来。
    （4）产生的 Mono<String> 确实发出“Hello World”。

主要的：上面的编号与实际的行顺序并不是错误的：它表示执行顺序。尽管 subscriberContext 是链的最后一部分，但它是首先执行的部分（因为它的订阅时间特性，以及订阅信号从下到上流动的事实）。

请注意，在你的操作符链中，你写入 Context 的位置和从中读取的位置的相对位置很重要: Context 是不可变的，其内容只能由上面的操作符看到，如下面的代码示例所示：
```
String key = "message";
Mono<String> r = Mono.just("Hello")
                     .subscriberContext(ctx -> ctx.put(key, "World")) 
                     .flatMap( s -> Mono.subscriberContext()
                                        .map( ctx -> s + " " + ctx.getOrDefault(key, "Stranger")));  

StepVerifier.create(r)
            .expectNext("Hello Stranger") 
            .verifyComplete();
```
    （1）Context 在链中写得太高了……
    （2）因此，在 flatMap 中，没有与 key 相关联的值。而是使用默认值。
    （3）由此产生的 Mono<String> 发出“Hello Stranger”。

下面的示例还演示了 Context 的不可变特性，以及 Mono.subscriberContext() 如何始终返回 subscriberContext 调用设置的 Context：
```
String key = "message";

Mono<String> r = Mono.subscriberContext() 
    .map( ctx -> ctx.put(key, "Hello")) 
    .flatMap( ctx -> Mono.subscriberContext()) 
    .map( ctx -> ctx.getOrDefault(key,"Default")); 

StepVerifier.create(r)
    .expectNext("Default") 
    .verifyComplete();
```
    （1）这是第一次写发生。
    （2）这是第二次写发生。
    （3）第一个 flatMap 看到第二个写。
    （4）第二个 flatMap 将第一个结果与第一次写入的值连接起来。
    （5）Mono 发出“Hello Reactor World”。

原因是 Context 与 Subscriber 是关联的，并且每个操作符通过从 Context 的下游 Subscriber 请求该 Context 来访问该 Context。

最后一个有趣的传播案例是在 flatMap 内部写入 Context，如下面示例所示：
```
String key = "message";
Mono<String> r =
        Mono.just("Hello")
            .flatMap( s -> Mono.subscriberContext()
                               .map( ctx -> s + " " + ctx.get(key))
            )
            .flatMap( s -> Mono.subscriberContext()
                               .map( ctx -> s + " " + ctx.get(key))
                               .subscriberContext(ctx -> ctx.put(key, "Reactor")) 
            )
            .subscriberContext(ctx -> ctx.put(key, "World")); 

StepVerifier.create(r)
            .expectNext("Hello World Reactor")
            .verifyComplete();
```
    （1）此 subscriberContext 不会影响其 flatMap 之外的任何内容。
    （2）这个 subscriberContext 影响主序列的 Context。

在上面的示例中，最终发出的值是“Hello-World Reactor”，而不是“Hello-Reactor-World”，因为编写“Reactor”的 subscriberContext 作为第二个 flatMap 的内部序列的一部分。因此，它不可见/通过主序列传播，并且第一个 flatMap 看不到它。传播+不变性在创建像 flatMap 这样的中间内部序列的操作符中隔离 Context。

### 8.8.5、完整示例

让我们考虑一个更真实的从 Context 中读取信息的库示例：一个反应式 HTTP 客户端，它将 Mono<String> 作为 PUT 的数据源，但也会寻找一个特定的 Context 键来向请求头添加一个相关 ID。

从用户的角度来看，可以如下调用它:
```
doPut("www.example.com", Mono.just("Walter"))
```
为了传播相关 ID，可以如下调用它：
```
doPut("www.example.com", Mono.just("Walter"))
    .subscriberContext(Context.of(HTTP_CORRELATION_ID, "2-j3r9afaf92j-afkaf"))
```
正如你在上面的代码片段中看到的，用户代码使用 subscriberContext 来用 HTTP_CORRELATION_ID 键值对填充 Context。操作符的上游是由 HTTP 客户端库返回的 Mono<Tuple2<Integer，String>>（HTTP 响应的简单表示）。因此，它有效地将信息从用户代码传递到库代码。

以下示例从库的角度显示模拟代码，该代码读取上下文，如果可以找到相关 ID，则“扩展请求”：
```
static final String HTTP_CORRELATION_ID = "reactive.http.library.correlationId";

Mono<Tuple2<Integer, String>> doPut(String url, Mono<String> data) {
    Mono<Tuple2<String, Optional<Object>>> dataAndContext =
            data.zipWith(Mono.subscriberContext() 
                             .map(c -> c.getOrEmpty(HTTP_CORRELATION_ID))); 

    return dataAndContext
            .<String>handle((dac, sink) -> {
                if (dac.getT2().isPresent()) { 
                    sink.next("PUT <" + dac.getT1() + "> sent to " + url + " with header X-Correlation-ID = " + dac.getT2().get());
                }
                else {
                    sink.next("PUT <" + dac.getT1() + "> sent to " + url);
                }
                sink.complete();
            })
            .map(msg -> Tuples.of(200, msg));
```
    （1）通过 Mono.subscriberContext() 具体化 Context。
    （2）提取相关 ID 键的值作为 Optional。
    （3）如果该键存在于上下文中，则使用相关 ID 作为头。

在库片段中，你可以看到它如何使用 Mono.subscriberContext() 压缩数据 Mono。这将为库提供 Tuple2<String,Context>，并且该上下文包含来自下游的 HTTP_CORRELATION_ID 条目（因为它位于订阅者的直接路径上）。

然后库代码使用 map 为该键提取一个 Optional<String>，如果条目存在，则使用传递的相关 ID 作为 X-Correlation-ID 头。最后一部分由上面的 handle 模拟。

验证使用相关ID的库代码的整个测试可以编写如下：
```
@Test
public void contextForLibraryReactivePut() {
    Mono<String> put = doPut("www.example.com", Mono.just("Walter"))
            .subscriberContext(Context.of(HTTP_CORRELATION_ID, "2-j3r9afaf92j-afkaf"))
            .filter(t -> t.getT1() < 300)
            .map(Tuple2::getT2);

    StepVerifier.create(put)
                .expectNext("PUT <Walter> sent to www.example.com with header X-Correlation-ID = 2-j3r9afaf92j-afkaf")
                .verifyComplete();
}
```
## 8.9、处理需要清理的对象

在非常特殊的情况下，应用程序可能会处理那些一旦不再使用就需要某种形式的清理的类型。这是一个高级场景，例如当你有引用计数对象或处理堆外对象时。Netty 的 ByteBuf 就是这两者的最好例子。

为了确保对此类对象进行正确的清理，你需要在逐个 Flux 的基础上以及在多个全局钩子（请参见[使用全局钩子](https://projectreactor.io/docs/core/3.2.11.RELEASE/reference/#hooks)）中对其进行调整：

    （1）doOnDiscard Flux/Mono 操作符
    （2）onOperatorError 钩子
    （3）onNextDropped 钩子
    （4）特定操作符的处理程序

这是必需的，因为每个钩子都考虑了特定的清理子集，用户可能希望实现特定的错误处理逻辑以及 onOperatorError 中的清理逻辑。

请注意，有些操作符不太适合处理需要清理的对象。例如，bufferWhen 可以引入重叠缓冲区, 这意味着上面的丢弃 “本地钩子” 可能会看到第一个缓冲区被丢弃，并清理它中的一个元素，该元素在第二个缓冲区中仍然有效。

重要的：为了清理，所有这些钩子必须是幂等的。在某些情况下，它们可能会被多次应用于同一物体。与执行类 instanceOf 检查的 doOnDiscard 操作符不同, 全局钩子也处理可以是任何 Object 的实例，由用户的实现来区分哪些实例需要清理，哪些不需要清理。

### 8.9.1、doOnDiscard 操作符/本地钩子

这个钩子已经被专门用于清理对象，否则这些对象将永远不会暴露在用户代码中。它的目的是作为在正常情况下操作的流的清理钩子（不是格式错误的推送过多项的源，该源被 onNextDropped 覆盖）。

它是局部的，在某种意义上，它是通过一个操作符激活的，并且只适用于给定的 Flux 或 Mono。

明显的情况包括从上游过滤元素的操作符。这些元素永远不会到达下一个操作符 (或最终订阅者)，但这是正常执行路径的一部分。因此，它们被传递给 doOnDiscard 钩子。例如：

    （1）filter：与过滤器不匹配的项被视为 “丢弃”。
    （2）skip：跳过的项被丢弃。
    （3）maxSize 小于 skip 的 buffer(maxSize,skip)：“丢弃缓冲区”，缓冲区之间的项被丢弃。
    （4）...

但是 doOnDiscard 不仅限于过滤运算符，也被内部为背压目的对数据进行排队的运算符使用。更具体地说，在取消的过程中，大多数时候这是很重要的: 当取消数据时，一个从其源预取数据，然后按需排放到其订阅者的操作符可能会有未发出的数据。此类操作符在取消时使用 doOnDiscard 钩子来清除其内部背压Queue。

警告：对 doOnDiscard(Class, Consumer) 的每个调用都是与其他调用相加的，在某种程度上，它只被其上游的操作符看到和使用。

### 8.9.2、onOperatorError 钩子

onOperatorError 旨在以横向方式修改错误（类似于 AOP catch-and-rethrow）。

当在处理 onNext 信号期间发生错误时，发出的元素将传递给 onOperatorError。

如果该类型的元素需要清理，则需要在 onOperatorError 钩子中实现它，可能需要在重写错误代码的基础上。

### 8.9.3、onNextDropped 钩子

对于格式不正确的 Publishers，可能存在这样的情况：一个操作符在预期没有元素的情况下（通常是在接收到 onError 或 onComplete 信号之后）接收一个元素。在这种情况下，意外元素被 “丢弃”，并传递给 onNextDropped 钩子。如果有需要清理的类型，则必须在 onNextDropped 挂钩中检测这些类型，并在那里实现清理代码。

### 8.9.4、特定操作符的处理器

一些作为其操作的一部分处理缓冲和/或收集值的操作符具有特定的处理器，用于收集的数据不会传播到下游的情况。如果将此类操作符与需要清理的类型一起使用，则需要在这些处理器中执行清理。

例如，distinct 具有这样的回调，当操作符终止 (或取消) 时调用该回调，以清除它用来判断元素是否为 distinct 的集合。默认情况下，集合是 HashSet，清理回调只是 Hashet::clear。但如果处理引用计数对象，则可能需要将其更改为更复杂的处理器，该处理器将在“clear()”之前 release 集合中的每个元素。

## 8.10、空安全

尽管 Java 不允许用它的类型系统来表示空安全性，Reactor 现在提供注解来声明 APIs 的空安全性，类似于 Spring Framework 5 提供的注解。

Reactor 利用这些注解，但它们也可以用于任何基于 Reactor 的 Java 项目中，以声明空安全 APIs。方法体中使用的类型的可空性不在此功能的范围内。

这些注解使用 JSR 305 注解（IntelliJ IDEA 等工具支持的休眠 JSR）进行元注解，以便向 Java 开发者提供与空安全相关的有用警告，以避免运行时出现 NullPointerException。JSR 305 元注解允许工具供应商以一种通用的方式提供空安全支持，而不必为 Reactor 注解提供硬代码支持。

注释：使用 Kotlin 1.1.5+ 不需要也不建议在项目类路径中依赖 JSR 305。

Kotlin 也使用它们，它本身支持空安全。请参阅此专用部分以了解更多详细信息。

reactor.util.annotation 包中提供了以下注解：

    （1）@NonNull 表示特定参数、返回值或字段不能为 null。(在 @ NonNullApi 应用的参数和返回值上不需要它)。
    （2）@Nullable 表示特定参数、返回值或字段可以为 null。
    （3）@NonNullApi 是一个包级注解，表示非空是参数和返回值的默认行为。

注释：还不支持泛型类型参数、变量和数组元素的可空性。有关最新信息，请参阅[问题 #878](https://github.com/reactor/reactor-core/issues/878)。
